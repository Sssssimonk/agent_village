{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "\n",
    "\n",
    "from llama_index import ServiceContext # configuration files for llama_index\n",
    "from llama_index.readers import StringIterableReader  # transform str into documents\n",
    "# from llama_index.response.notebook_utils import display_response\n",
    "from llama_index import Document, VectorStoreIndex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007149219512939453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544e634de9824f6493411f97ef9d264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "hf_token = \"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\"\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    query_wrapper_prompt=PromptTemplate(\"<s> [INST] {query_str} [/INST] \"),\n",
    "    context_window=3900,\n",
    "    model_kwargs={\"token\": hf_token, \"quantization_config\": quantization_config},\n",
    "    tokenizer_kwargs={\"token\": hf_token},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
    "texts = ['a', \"a\", 'b', 'c']\n",
    "# text_list = ['hello', 'world']\n",
    "# documents = [Document(text=t) for t in text_list]           The same as StringIterableReader\n",
    "documents = StringIterableReader().load_data(texts=texts)   \n",
    "documents\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=3900, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7fb1a4b46d30>, tokenizer_name='BAAI/bge-small-en-v1.5', max_length=512, pooling=<Pooling.CLS: 'cls'>, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7fb1a4b46d30>, id_func=<function default_id_func at 0x7fb125d1ea60>, chunk_size=1024, chunk_overlap=200, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.logger.base.LlamaLogger object at 0x7fb184429100>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7fb1a4b46d30>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Based on the provided context information, the answer to the query \"Who is Tom?\" is not possible to determine with certainty. The context information provided is:\\n\\n\"a\"\\n\\nWithout any additional information or prior knowledge, it is not possible to determine who \"Tom\" is or what he might be referring to. The term \"Tom\" could refer to any person, place, thing, or concept, and without more context or information, it is impossible to provide a definitive answer to the query.', source_nodes=[NodeWithScore(node=TextNode(id_='83c513f8-5765-499e-afaa-93accf907fca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ed352519-7735-44ab-b7e8-7f4ec0aa2267', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5f546eb4606b5c2b7d2a449a5cc2bbb477ed5a246c7051ce871b12f2dbfc8419'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e120fdac-5daf-4d64-8665-d2ceab8fc354', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f546eb4606b5c2b7d2a449a5cc2bbb477ed5a246c7051ce871b12f2dbfc8419'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='92dad617-ce26-4382-bda6-a0fa64de5cfd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef2a875407aca2dd75a7a1dccc3b202918a9bc8e543e0b3def3f34ccd5e56a7b')}, text='a', start_char_idx=0, end_char_idx=1, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.46557391039041923)], metadata={'83c513f8-5765-499e-afaa-93accf907fca': {}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query_engine = vector_index.as_query_engine() #response_mode=\"compact\"\n",
    "\n",
    "response = query_engine.query(\"Who is tom\")\n",
    "\n",
    "# response.response     get the raw text output \n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Based on the context information provided, the answer to the query \"Who is Tom?\" is:\\n\\nTom is a school teacher who lives in the village and is in his late thirties. He is kind, dedicated, and has a passion for teaching and helping others. He is well-respected in the community and loved by his students for his patience and understanding.',\n",
       " 'source_nodes': [NodeWithScore(node=TextNode(id_='6fd73eb3-a697-45df-b7ec-227b633b6fdd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='009f3113-30bd-4262-8331-d0a4183138e1', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='556efb9aefdd2bb995bb01fbd0514f44c3bd5b9fb7946545b0f3f743a8093e3d')}, text='Tom is a kind and dedicated school teacher who has been living in the village his entire life. He is in his late thirties and has a passion for teaching and helping others. Tom is well-respected in the community and is loved by his students for his patience and understanding.', start_char_idx=0, end_char_idx=276, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.750976738387901)],\n",
       " 'metadata': {'6fd73eb3-a697-45df-b7ec-227b633b6fdd': {}}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.ref_doc_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga_kernel",
   "language": "python",
   "name": "ga_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
